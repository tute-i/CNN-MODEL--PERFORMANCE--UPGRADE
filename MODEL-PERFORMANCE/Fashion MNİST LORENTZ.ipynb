{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMRvzxA1yR9OheemvY+nO71"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VHo8HEiQuV1U","executionInfo":{"status":"ok","timestamp":1687270655296,"user_tz":-180,"elapsed":16082,"user":{"displayName":"Tuba Artar misir","userId":"06583584563187541524"}},"outputId":"b9ec8f21-4fbd-42da-93d1-f15b83ce9c74"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 26421880/26421880 [00:02<00:00, 11765553.65it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n","\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 29515/29515 [00:00<00:00, 206719.64it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n","\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 4422102/4422102 [00:01<00:00, 3889760.05it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n","\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5148/5148 [00:00<00:00, 3988966.75it/s]"]},{"output_type":"stream","name":"stdout","text":["Extracting ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n","\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["import torch\n","from torchvision import datasets, transforms\n","\n","# Veri dönüşümleri\n","transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.5,), (0.5,))  # Fashion-MNIST veri seti için normalize işlemi\n","])\n","\n","# Fashion-MNIST veri setini yükleme\n","train_dataset = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n","test_dataset = datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)\n","\n","# Veri yükleyicilerini oluşturma\n","batch_size = 64\n","train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torchvision import datasets, transforms\n","\n","\n","# Sinir ağı modeli\n","class ClassifierModule(nn.Module):\n","    def __init__(self):\n","        super(ClassifierModule, self).__init__()\n","        self.fc1 = nn.Linear(784, 512)\n","        self.fc2 = nn.Linear(512, 256)\n","        self.fc3 = nn.Linear(256, 10)\n","        self.relu = nn.ReLU()\n","        self.softmax = nn.Softmax(dim=1)\n","\n","    def forward(self, x):\n","        x = x.view(x.size(0), -1)\n","        x = self.relu(self.fc1(x))\n","        x = self.relu(self.fc2(x))\n","        x = self.fc3(x)\n","        x = self.softmax(x)\n","        return x\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = ClassifierModule().to(device)\n","\n","# Loss fonksiyonu ve optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","# Eğitim döngüsü\n","def train(model, dataloader, criterion, optimizer, device):\n","    model.train()\n","    running_loss = 0.0\n","    for batch_idx, (data, target) in enumerate(dataloader):\n","        data, target = data.to(device), target.to(device)\n","        optimizer.zero_grad()\n","        output = model(data)\n","        loss = criterion(output, target)\n","        loss.backward()\n","        optimizer.step()\n","        running_loss += loss.item()\n","    return running_loss / len(dataloader)\n","\n","# Evaluation fonksiyonu\n","def evaluate(model, dataloader, criterion, device):\n","    model.eval()\n","    running_loss = 0.0\n","    correct = 0\n","    total = 0\n","    with torch.no_grad():\n","        for batch_idx, (data, target) in enumerate(dataloader):\n","            data, target = data.to(device), target.to(device)\n","            output = model(data)\n","            loss = criterion(output, target)\n","            running_loss += loss.item()\n","            _, predicted = output.max(1)\n","            correct += predicted.eq(target).sum().item()\n","            total += target.size(0)\n","    return running_loss / len(dataloader), correct / total\n","\n","# Model eğitimi\n","num_epochs = 100\n","\n","for epoch in range(num_epochs):\n","    train_loss = train(model, train_loader, criterion, optimizer, device)\n","    test_loss, test_accuracy = evaluate(model, test_loader, criterion, device)\n","    print(f\"Epoch {epoch+1}/{num_epochs}: Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"thHkJmaJufHI","executionInfo":{"status":"ok","timestamp":1687274253572,"user_tz":-180,"elapsed":3571223,"user":{"displayName":"Tuba Artar misir","userId":"06583584563187541524"}},"outputId":"cd4fb787-48e0-41d8-983f-c9c9fdb6aa44"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100: Train Loss: 1.6857, Test Loss: 1.6688, Test Accuracy: 0.7900\n","Epoch 2/100: Train Loss: 1.6415, Test Loss: 1.6509, Test Accuracy: 0.8100\n","Epoch 3/100: Train Loss: 1.6352, Test Loss: 1.6329, Test Accuracy: 0.8280\n","Epoch 4/100: Train Loss: 1.6291, Test Loss: 1.6341, Test Accuracy: 0.8261\n","Epoch 5/100: Train Loss: 1.6287, Test Loss: 1.6521, Test Accuracy: 0.8090\n","Epoch 6/100: Train Loss: 1.6247, Test Loss: 1.6372, Test Accuracy: 0.8232\n","Epoch 7/100: Train Loss: 1.6265, Test Loss: 1.6364, Test Accuracy: 0.8241\n","Epoch 8/100: Train Loss: 1.6227, Test Loss: 1.6362, Test Accuracy: 0.8245\n","Epoch 9/100: Train Loss: 1.6214, Test Loss: 1.6202, Test Accuracy: 0.8407\n","Epoch 10/100: Train Loss: 1.6234, Test Loss: 1.6311, Test Accuracy: 0.8297\n","Epoch 11/100: Train Loss: 1.6219, Test Loss: 1.6234, Test Accuracy: 0.8367\n","Epoch 12/100: Train Loss: 1.6201, Test Loss: 1.6291, Test Accuracy: 0.8310\n","Epoch 13/100: Train Loss: 1.6153, Test Loss: 1.6334, Test Accuracy: 0.8273\n","Epoch 14/100: Train Loss: 1.6119, Test Loss: 1.6175, Test Accuracy: 0.8426\n","Epoch 15/100: Train Loss: 1.6151, Test Loss: 1.6245, Test Accuracy: 0.8359\n","Epoch 16/100: Train Loss: 1.6110, Test Loss: 1.6249, Test Accuracy: 0.8359\n","Epoch 17/100: Train Loss: 1.6114, Test Loss: 1.6411, Test Accuracy: 0.8199\n","Epoch 18/100: Train Loss: 1.6135, Test Loss: 1.6284, Test Accuracy: 0.8320\n","Epoch 19/100: Train Loss: 1.6183, Test Loss: 1.6265, Test Accuracy: 0.8340\n","Epoch 20/100: Train Loss: 1.6144, Test Loss: 1.6232, Test Accuracy: 0.8372\n","Epoch 21/100: Train Loss: 1.6073, Test Loss: 1.6209, Test Accuracy: 0.8397\n","Epoch 22/100: Train Loss: 1.6110, Test Loss: 1.6426, Test Accuracy: 0.8185\n","Epoch 23/100: Train Loss: 1.6117, Test Loss: 1.6208, Test Accuracy: 0.8396\n","Epoch 24/100: Train Loss: 1.6207, Test Loss: 1.6236, Test Accuracy: 0.8370\n","Epoch 25/100: Train Loss: 1.6170, Test Loss: 1.6276, Test Accuracy: 0.8331\n","Epoch 26/100: Train Loss: 1.6140, Test Loss: 1.6201, Test Accuracy: 0.8406\n","Epoch 27/100: Train Loss: 1.6158, Test Loss: 1.6259, Test Accuracy: 0.8348\n","Epoch 28/100: Train Loss: 1.6162, Test Loss: 1.6257, Test Accuracy: 0.8354\n","Epoch 29/100: Train Loss: 1.6175, Test Loss: 1.6414, Test Accuracy: 0.8192\n","Epoch 30/100: Train Loss: 1.6226, Test Loss: 1.6174, Test Accuracy: 0.8435\n","Epoch 31/100: Train Loss: 1.6158, Test Loss: 1.6256, Test Accuracy: 0.8351\n","Epoch 32/100: Train Loss: 1.6172, Test Loss: 1.6307, Test Accuracy: 0.8302\n","Epoch 33/100: Train Loss: 1.6149, Test Loss: 1.6369, Test Accuracy: 0.8232\n","Epoch 34/100: Train Loss: 1.6217, Test Loss: 1.6383, Test Accuracy: 0.8221\n","Epoch 35/100: Train Loss: 1.6154, Test Loss: 1.6315, Test Accuracy: 0.8293\n","Epoch 36/100: Train Loss: 1.6183, Test Loss: 1.6365, Test Accuracy: 0.8245\n","Epoch 37/100: Train Loss: 1.6184, Test Loss: 1.6378, Test Accuracy: 0.8230\n","Epoch 38/100: Train Loss: 1.6160, Test Loss: 1.6349, Test Accuracy: 0.8255\n","Epoch 39/100: Train Loss: 1.6119, Test Loss: 1.6536, Test Accuracy: 0.8069\n","Epoch 40/100: Train Loss: 1.6184, Test Loss: 1.6416, Test Accuracy: 0.8197\n","Epoch 41/100: Train Loss: 1.6202, Test Loss: 1.6424, Test Accuracy: 0.8185\n","Epoch 42/100: Train Loss: 1.6147, Test Loss: 1.6229, Test Accuracy: 0.8374\n","Epoch 43/100: Train Loss: 1.6089, Test Loss: 1.6256, Test Accuracy: 0.8348\n","Epoch 44/100: Train Loss: 1.6210, Test Loss: 1.6301, Test Accuracy: 0.8313\n","Epoch 45/100: Train Loss: 1.6241, Test Loss: 1.6525, Test Accuracy: 0.8082\n","Epoch 46/100: Train Loss: 1.6150, Test Loss: 1.6278, Test Accuracy: 0.8329\n","Epoch 47/100: Train Loss: 1.6198, Test Loss: 1.6213, Test Accuracy: 0.8394\n","Epoch 48/100: Train Loss: 1.6137, Test Loss: 1.6511, Test Accuracy: 0.8096\n","Epoch 49/100: Train Loss: 1.6156, Test Loss: 1.6181, Test Accuracy: 0.8428\n","Epoch 50/100: Train Loss: 1.6208, Test Loss: 1.6381, Test Accuracy: 0.8225\n","Epoch 51/100: Train Loss: 1.6209, Test Loss: 1.6276, Test Accuracy: 0.8330\n","Epoch 52/100: Train Loss: 1.6117, Test Loss: 1.6336, Test Accuracy: 0.8276\n","Epoch 53/100: Train Loss: 1.6190, Test Loss: 1.6200, Test Accuracy: 0.8408\n","Epoch 54/100: Train Loss: 1.6134, Test Loss: 1.6214, Test Accuracy: 0.8392\n","Epoch 55/100: Train Loss: 1.6216, Test Loss: 1.6416, Test Accuracy: 0.8193\n","Epoch 56/100: Train Loss: 1.6272, Test Loss: 1.6291, Test Accuracy: 0.8312\n","Epoch 57/100: Train Loss: 1.6153, Test Loss: 1.6374, Test Accuracy: 0.8233\n","Epoch 58/100: Train Loss: 1.6129, Test Loss: 1.6166, Test Accuracy: 0.8444\n","Epoch 59/100: Train Loss: 1.6143, Test Loss: 1.6311, Test Accuracy: 0.8297\n","Epoch 60/100: Train Loss: 1.6126, Test Loss: 1.6122, Test Accuracy: 0.8485\n","Epoch 61/100: Train Loss: 1.6164, Test Loss: 1.6267, Test Accuracy: 0.8342\n","Epoch 62/100: Train Loss: 1.6187, Test Loss: 1.6533, Test Accuracy: 0.8075\n","Epoch 63/100: Train Loss: 1.6234, Test Loss: 1.6328, Test Accuracy: 0.8279\n","Epoch 64/100: Train Loss: 1.6232, Test Loss: 1.6234, Test Accuracy: 0.8369\n","Epoch 65/100: Train Loss: 1.6176, Test Loss: 1.6238, Test Accuracy: 0.8368\n","Epoch 66/100: Train Loss: 1.6172, Test Loss: 1.6277, Test Accuracy: 0.8331\n","Epoch 67/100: Train Loss: 1.6167, Test Loss: 1.6292, Test Accuracy: 0.8315\n","Epoch 68/100: Train Loss: 1.6237, Test Loss: 1.6571, Test Accuracy: 0.8037\n","Epoch 69/100: Train Loss: 1.6216, Test Loss: 1.6511, Test Accuracy: 0.8099\n","Epoch 70/100: Train Loss: 1.6156, Test Loss: 1.6678, Test Accuracy: 0.7932\n","Epoch 71/100: Train Loss: 1.6211, Test Loss: 1.6493, Test Accuracy: 0.8113\n","Epoch 72/100: Train Loss: 1.6308, Test Loss: 1.6202, Test Accuracy: 0.8408\n","Epoch 73/100: Train Loss: 1.6178, Test Loss: 1.6267, Test Accuracy: 0.8339\n","Epoch 74/100: Train Loss: 1.6211, Test Loss: 1.6595, Test Accuracy: 0.8010\n","Epoch 75/100: Train Loss: 1.6219, Test Loss: 1.6468, Test Accuracy: 0.8142\n","Epoch 76/100: Train Loss: 1.6215, Test Loss: 1.6182, Test Accuracy: 0.8428\n","Epoch 77/100: Train Loss: 1.6341, Test Loss: 1.6399, Test Accuracy: 0.8210\n","Epoch 78/100: Train Loss: 1.6183, Test Loss: 1.6502, Test Accuracy: 0.8103\n","Epoch 79/100: Train Loss: 1.6258, Test Loss: 1.6723, Test Accuracy: 0.7885\n","Epoch 80/100: Train Loss: 1.6257, Test Loss: 1.6667, Test Accuracy: 0.7938\n","Epoch 81/100: Train Loss: 1.6188, Test Loss: 1.6149, Test Accuracy: 0.8455\n","Epoch 82/100: Train Loss: 1.6078, Test Loss: 1.6277, Test Accuracy: 0.8329\n","Epoch 83/100: Train Loss: 1.6187, Test Loss: 1.6306, Test Accuracy: 0.8300\n","Epoch 84/100: Train Loss: 1.6207, Test Loss: 1.6359, Test Accuracy: 0.8247\n","Epoch 85/100: Train Loss: 1.6230, Test Loss: 1.6288, Test Accuracy: 0.8320\n","Epoch 86/100: Train Loss: 1.6094, Test Loss: 1.6178, Test Accuracy: 0.8429\n","Epoch 87/100: Train Loss: 1.6186, Test Loss: 1.6144, Test Accuracy: 0.8466\n","Epoch 88/100: Train Loss: 1.6235, Test Loss: 1.6303, Test Accuracy: 0.8305\n","Epoch 89/100: Train Loss: 1.6187, Test Loss: 1.6383, Test Accuracy: 0.8222\n","Epoch 90/100: Train Loss: 1.6239, Test Loss: 1.6376, Test Accuracy: 0.8235\n","Epoch 91/100: Train Loss: 1.6238, Test Loss: 1.6279, Test Accuracy: 0.8327\n","Epoch 92/100: Train Loss: 1.6194, Test Loss: 1.6200, Test Accuracy: 0.8412\n","Epoch 93/100: Train Loss: 1.6199, Test Loss: 1.6372, Test Accuracy: 0.8240\n","Epoch 94/100: Train Loss: 1.6276, Test Loss: 1.6482, Test Accuracy: 0.8125\n","Epoch 95/100: Train Loss: 1.6505, Test Loss: 1.6738, Test Accuracy: 0.7875\n","Epoch 96/100: Train Loss: 1.6301, Test Loss: 1.6366, Test Accuracy: 0.8243\n","Epoch 97/100: Train Loss: 1.6360, Test Loss: 1.6275, Test Accuracy: 0.8328\n","Epoch 98/100: Train Loss: 1.6357, Test Loss: 1.6382, Test Accuracy: 0.8223\n","Epoch 99/100: Train Loss: 1.6201, Test Loss: 1.6388, Test Accuracy: 0.8217\n","Epoch 100/100: Train Loss: 1.6306, Test Loss: 1.6246, Test Accuracy: 0.8366\n"]}]},{"cell_type":"code","source":["def apply_lorentz_transformation(data):\n","    # Lorentz dönüşümü uygulama kodu\n","    beta = 0.99\n","    gamma = 1 / (torch.sqrt(torch.tensor(1 - beta**2)) if beta < 1 else float('inf'))  # Lorentz faktörü\n","\n","    data_tensor = torch.tensor(data, dtype=torch.float32)  # Data'yı Tensor'a dönüştür\n","    transformed_data = gamma * (data_tensor - beta * data_tensor)\n","    return transformed_data"],"metadata":{"id":"muxZvtDbuv4V","executionInfo":{"status":"ok","timestamp":1687274275168,"user_tz":-180,"elapsed":398,"user":{"displayName":"Tuba Artar misir","userId":"06583584563187541524"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torchvision import datasets, transforms\n","\n","\n","# Eğitim döngüsü\n","def train(model, dataloader, criterion, optimizer, device):\n","    model.train()\n","    running_loss = 0.0\n","    for batch_idx, (data, target) in enumerate(dataloader):\n","        data, target = data.to(device), target.to(device)\n","\n","        # Lorentz dönüşümü uygulama\n","        data = apply_lorentz_transformation(data)\n","\n","        optimizer.zero_grad()\n","        output = model(data)\n","        loss = criterion(output, target)\n","        loss.backward()\n","        optimizer.step()\n","        running_loss += loss.item()\n","    return running_loss / len(dataloader)\n","\n","# Evaluation fonksiyonu\n","def evaluate(model, dataloader, criterion, device):\n","    model.eval()\n","    running_loss = 0.0\n","    correct = 0\n","    total = 0\n","    with torch.no_grad():\n","        for batch_idx, (data, target) in enumerate(dataloader):\n","            data, target = data.to(device), target.to(device)\n","\n","            # Lorentz dönüşümü uygulama\n","            data = apply_lorentz_transformation(data)\n","\n","            output = model(data)\n","            loss = criterion(output, target)\n","            running_loss += loss.item()\n","            _, predicted = output.max(1)\n","            correct += predicted.eq(target).sum().item()\n","            total += target.size(0)\n","    return running_loss / len(dataloader), correct / total\n","\n","# Model eğitimi\n","num_epochs = 100\n","\n","for epoch in range(num_epochs):\n","    train_loss = train(model, train_loader, criterion, optimizer, device)\n","    test_loss, test_accuracy = evaluate(model, test_loader, criterion, device)\n","    print(f\"Epoch {epoch+1}/{num_epochs}: Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VnjN6qeVu1rI","executionInfo":{"status":"ok","timestamp":1687279045112,"user_tz":-180,"elapsed":4724432,"user":{"displayName":"Tuba Artar misir","userId":"06583584563187541524"}},"outputId":"a9ef4a5e-22f6-485e-c5a4-d4fb6875a389"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-4-ca63d6f88a5e>:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  data_tensor = torch.tensor(data, dtype=torch.float32)  # Data'yı Tensor'a dönüştür\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/100: Train Loss: 1.5955, Test Loss: 1.6118, Test Accuracy: 0.8488\n","Epoch 2/100: Train Loss: 1.5904, Test Loss: 1.6060, Test Accuracy: 0.8544\n","Epoch 3/100: Train Loss: 1.5896, Test Loss: 1.6073, Test Accuracy: 0.8536\n","Epoch 4/100: Train Loss: 1.5897, Test Loss: 1.6069, Test Accuracy: 0.8534\n","Epoch 5/100: Train Loss: 1.5871, Test Loss: 1.6000, Test Accuracy: 0.8604\n","Epoch 6/100: Train Loss: 1.5854, Test Loss: 1.6010, Test Accuracy: 0.8597\n","Epoch 7/100: Train Loss: 1.5847, Test Loss: 1.6062, Test Accuracy: 0.8543\n","Epoch 8/100: Train Loss: 1.5832, Test Loss: 1.6031, Test Accuracy: 0.8576\n","Epoch 9/100: Train Loss: 1.5820, Test Loss: 1.6030, Test Accuracy: 0.8574\n","Epoch 10/100: Train Loss: 1.5795, Test Loss: 1.6038, Test Accuracy: 0.8565\n","Epoch 11/100: Train Loss: 1.5809, Test Loss: 1.5963, Test Accuracy: 0.8640\n","Epoch 12/100: Train Loss: 1.5767, Test Loss: 1.5977, Test Accuracy: 0.8624\n","Epoch 13/100: Train Loss: 1.5774, Test Loss: 1.6030, Test Accuracy: 0.8568\n","Epoch 14/100: Train Loss: 1.5777, Test Loss: 1.5950, Test Accuracy: 0.8649\n","Epoch 15/100: Train Loss: 1.5740, Test Loss: 1.5904, Test Accuracy: 0.8700\n","Epoch 16/100: Train Loss: 1.5745, Test Loss: 1.5934, Test Accuracy: 0.8668\n","Epoch 17/100: Train Loss: 1.5734, Test Loss: 1.5919, Test Accuracy: 0.8678\n","Epoch 18/100: Train Loss: 1.5734, Test Loss: 1.5897, Test Accuracy: 0.8702\n","Epoch 19/100: Train Loss: 1.5737, Test Loss: 1.5922, Test Accuracy: 0.8683\n","Epoch 20/100: Train Loss: 1.5706, Test Loss: 1.5972, Test Accuracy: 0.8631\n","Epoch 21/100: Train Loss: 1.5721, Test Loss: 1.5925, Test Accuracy: 0.8675\n","Epoch 22/100: Train Loss: 1.5692, Test Loss: 1.5891, Test Accuracy: 0.8716\n","Epoch 23/100: Train Loss: 1.5686, Test Loss: 1.5917, Test Accuracy: 0.8688\n","Epoch 24/100: Train Loss: 1.5673, Test Loss: 1.5880, Test Accuracy: 0.8719\n","Epoch 25/100: Train Loss: 1.5670, Test Loss: 1.5893, Test Accuracy: 0.8710\n","Epoch 26/100: Train Loss: 1.5672, Test Loss: 1.5888, Test Accuracy: 0.8715\n","Epoch 27/100: Train Loss: 1.5647, Test Loss: 1.5903, Test Accuracy: 0.8697\n","Epoch 28/100: Train Loss: 1.5637, Test Loss: 1.5869, Test Accuracy: 0.8735\n","Epoch 29/100: Train Loss: 1.5628, Test Loss: 1.5849, Test Accuracy: 0.8753\n","Epoch 30/100: Train Loss: 1.5636, Test Loss: 1.5904, Test Accuracy: 0.8699\n","Epoch 31/100: Train Loss: 1.5621, Test Loss: 1.5863, Test Accuracy: 0.8741\n","Epoch 32/100: Train Loss: 1.5596, Test Loss: 1.5888, Test Accuracy: 0.8714\n","Epoch 33/100: Train Loss: 1.5599, Test Loss: 1.5907, Test Accuracy: 0.8698\n","Epoch 34/100: Train Loss: 1.5632, Test Loss: 1.5879, Test Accuracy: 0.8720\n","Epoch 35/100: Train Loss: 1.5589, Test Loss: 1.5852, Test Accuracy: 0.8746\n","Epoch 36/100: Train Loss: 1.5599, Test Loss: 1.5845, Test Accuracy: 0.8758\n","Epoch 37/100: Train Loss: 1.5582, Test Loss: 1.5854, Test Accuracy: 0.8747\n","Epoch 38/100: Train Loss: 1.5582, Test Loss: 1.5847, Test Accuracy: 0.8752\n","Epoch 39/100: Train Loss: 1.5563, Test Loss: 1.5824, Test Accuracy: 0.8781\n","Epoch 40/100: Train Loss: 1.5572, Test Loss: 1.5840, Test Accuracy: 0.8760\n","Epoch 41/100: Train Loss: 1.5545, Test Loss: 1.5880, Test Accuracy: 0.8721\n","Epoch 42/100: Train Loss: 1.5569, Test Loss: 1.5841, Test Accuracy: 0.8761\n","Epoch 43/100: Train Loss: 1.5542, Test Loss: 1.5845, Test Accuracy: 0.8757\n","Epoch 44/100: Train Loss: 1.5541, Test Loss: 1.5826, Test Accuracy: 0.8773\n","Epoch 45/100: Train Loss: 1.5522, Test Loss: 1.5809, Test Accuracy: 0.8798\n","Epoch 46/100: Train Loss: 1.5541, Test Loss: 1.5885, Test Accuracy: 0.8717\n","Epoch 47/100: Train Loss: 1.5514, Test Loss: 1.5789, Test Accuracy: 0.8810\n","Epoch 48/100: Train Loss: 1.5530, Test Loss: 1.5806, Test Accuracy: 0.8792\n","Epoch 49/100: Train Loss: 1.5509, Test Loss: 1.5820, Test Accuracy: 0.8784\n","Epoch 50/100: Train Loss: 1.5503, Test Loss: 1.5816, Test Accuracy: 0.8786\n","Epoch 51/100: Train Loss: 1.5500, Test Loss: 1.5793, Test Accuracy: 0.8811\n","Epoch 52/100: Train Loss: 1.5487, Test Loss: 1.5803, Test Accuracy: 0.8802\n","Epoch 53/100: Train Loss: 1.5491, Test Loss: 1.5805, Test Accuracy: 0.8794\n","Epoch 54/100: Train Loss: 1.5468, Test Loss: 1.5809, Test Accuracy: 0.8793\n","Epoch 55/100: Train Loss: 1.5457, Test Loss: 1.5824, Test Accuracy: 0.8775\n","Epoch 56/100: Train Loss: 1.5469, Test Loss: 1.5822, Test Accuracy: 0.8775\n","Epoch 57/100: Train Loss: 1.5465, Test Loss: 1.5802, Test Accuracy: 0.8802\n","Epoch 58/100: Train Loss: 1.5465, Test Loss: 1.5813, Test Accuracy: 0.8783\n","Epoch 59/100: Train Loss: 1.5448, Test Loss: 1.5782, Test Accuracy: 0.8823\n","Epoch 60/100: Train Loss: 1.5450, Test Loss: 1.5835, Test Accuracy: 0.8765\n","Epoch 61/100: Train Loss: 1.5447, Test Loss: 1.5788, Test Accuracy: 0.8817\n","Epoch 62/100: Train Loss: 1.5439, Test Loss: 1.5763, Test Accuracy: 0.8837\n","Epoch 63/100: Train Loss: 1.5429, Test Loss: 1.5783, Test Accuracy: 0.8815\n","Epoch 64/100: Train Loss: 1.5422, Test Loss: 1.5776, Test Accuracy: 0.8829\n","Epoch 65/100: Train Loss: 1.5415, Test Loss: 1.5796, Test Accuracy: 0.8807\n","Epoch 66/100: Train Loss: 1.5417, Test Loss: 1.5793, Test Accuracy: 0.8809\n","Epoch 67/100: Train Loss: 1.5425, Test Loss: 1.5753, Test Accuracy: 0.8845\n","Epoch 68/100: Train Loss: 1.5406, Test Loss: 1.5807, Test Accuracy: 0.8799\n","Epoch 69/100: Train Loss: 1.5404, Test Loss: 1.5806, Test Accuracy: 0.8795\n","Epoch 70/100: Train Loss: 1.5390, Test Loss: 1.5793, Test Accuracy: 0.8808\n","Epoch 71/100: Train Loss: 1.5395, Test Loss: 1.5758, Test Accuracy: 0.8845\n","Epoch 72/100: Train Loss: 1.5403, Test Loss: 1.5772, Test Accuracy: 0.8828\n","Epoch 73/100: Train Loss: 1.5390, Test Loss: 1.5771, Test Accuracy: 0.8825\n","Epoch 74/100: Train Loss: 1.5382, Test Loss: 1.5758, Test Accuracy: 0.8843\n","Epoch 75/100: Train Loss: 1.5374, Test Loss: 1.5758, Test Accuracy: 0.8844\n","Epoch 76/100: Train Loss: 1.5383, Test Loss: 1.5779, Test Accuracy: 0.8824\n","Epoch 77/100: Train Loss: 1.5371, Test Loss: 1.5747, Test Accuracy: 0.8855\n","Epoch 78/100: Train Loss: 1.5365, Test Loss: 1.5742, Test Accuracy: 0.8867\n","Epoch 79/100: Train Loss: 1.5363, Test Loss: 1.5754, Test Accuracy: 0.8848\n","Epoch 80/100: Train Loss: 1.5357, Test Loss: 1.5742, Test Accuracy: 0.8857\n","Epoch 81/100: Train Loss: 1.5360, Test Loss: 1.5768, Test Accuracy: 0.8832\n","Epoch 82/100: Train Loss: 1.5349, Test Loss: 1.5768, Test Accuracy: 0.8837\n","Epoch 83/100: Train Loss: 1.5358, Test Loss: 1.5817, Test Accuracy: 0.8779\n","Epoch 84/100: Train Loss: 1.5343, Test Loss: 1.5751, Test Accuracy: 0.8851\n","Epoch 85/100: Train Loss: 1.5337, Test Loss: 1.5743, Test Accuracy: 0.8853\n","Epoch 86/100: Train Loss: 1.5339, Test Loss: 1.5764, Test Accuracy: 0.8837\n","Epoch 87/100: Train Loss: 1.5340, Test Loss: 1.5793, Test Accuracy: 0.8808\n","Epoch 88/100: Train Loss: 1.5331, Test Loss: 1.5804, Test Accuracy: 0.8798\n","Epoch 89/100: Train Loss: 1.5335, Test Loss: 1.5726, Test Accuracy: 0.8880\n","Epoch 90/100: Train Loss: 1.5338, Test Loss: 1.5732, Test Accuracy: 0.8860\n","Epoch 91/100: Train Loss: 1.5337, Test Loss: 1.5759, Test Accuracy: 0.8843\n","Epoch 92/100: Train Loss: 1.5342, Test Loss: 1.5735, Test Accuracy: 0.8866\n","Epoch 93/100: Train Loss: 1.5340, Test Loss: 1.5740, Test Accuracy: 0.8861\n","Epoch 94/100: Train Loss: 1.5322, Test Loss: 1.5731, Test Accuracy: 0.8871\n","Epoch 95/100: Train Loss: 1.5309, Test Loss: 1.5729, Test Accuracy: 0.8872\n","Epoch 96/100: Train Loss: 1.5316, Test Loss: 1.5775, Test Accuracy: 0.8831\n","Epoch 97/100: Train Loss: 1.5317, Test Loss: 1.5769, Test Accuracy: 0.8825\n","Epoch 98/100: Train Loss: 1.5308, Test Loss: 1.5752, Test Accuracy: 0.8851\n","Epoch 99/100: Train Loss: 1.5313, Test Loss: 1.5821, Test Accuracy: 0.8775\n","Epoch 100/100: Train Loss: 1.5310, Test Loss: 1.5739, Test Accuracy: 0.8864\n"]}]}]}